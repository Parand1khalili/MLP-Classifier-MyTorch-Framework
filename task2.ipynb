{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac2b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mytorch.tensor import Tensor\n",
    "from mytorch.model import Model\n",
    "from mytorch.layer.linear import Linear\n",
    "from mytorch.activation import tanh, sigmoid\n",
    "from mytorch.activation.softmax import softmax\n",
    "from mytorch.loss.mse import MeanSquaredError\n",
    "from mytorch.optimizer import Adam, SGD, Momentum, RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04062269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "column_names = [\"ID\", \"Diagnosis\"] + [f\"Feature_{i}\" for i in range(1,31)]\n",
    "df = pd.read_csv(\"wdbc.data\", header=None, names=column_names, usecols=range(32))\n",
    "\n",
    "df[\"Diagnosis\"] = df[\"Diagnosis\"].map({\"M\": 1, \"B\": 0})\n",
    "\n",
    "X = df.iloc[:, 2:].values  \n",
    "y = df[\"Diagnosis\"].values \n",
    "\n",
    "np.random.seed(25)\n",
    "indices = np.random.permutation(len(X))\n",
    "X = X[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e62c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT INTO TRAIN & TEST\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "#CONVERT NUMPY ARRAYS TO MYTORCH TENSORS\n",
    "X_train_tensor = Tensor(X_train, requires_grad=True)\n",
    "y_train_tensor = Tensor(y_train.reshape(-1,1), requires_grad=False)  \n",
    "X_test_tensor = Tensor(X_test, requires_grad=False)\n",
    "y_test_tensor = Tensor(y_test.reshape(-1,1), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE A MODEL \n",
    "class BreastCancerModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = Linear(30, 16) \n",
    "        self.layer2 = Linear(16, 1)   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # use tanh and sigmoid for the final output (binary classification)\n",
    "        x = self.layer1.forward(x)\n",
    "        x = tanh(x)\n",
    "        x = self.layer2.forward(x)\n",
    "        x = sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = BreastCancerModel()\n",
    "\n",
    "# LOSS FUNCTION (MSE) & OPTIMIZER (ADAM, ETC.)\n",
    "criterion = MeanSquaredError\n",
    "optimizer = Adam(model.parameters(), lr=0.005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccc176f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 61.31868131868132\n",
      "train accuracy = 67.6923076923077\n",
      "train accuracy = 63.95604395604395\n",
      "train accuracy = 63.29670329670329\n",
      "train accuracy = 63.29670329670329\n",
      "train accuracy = 63.29670329670329\n",
      "train accuracy = 63.29670329670329\n",
      "train accuracy = 63.29670329670329\n",
      "train accuracy = 87.03296703296704\n",
      "Epoch [10/2000], Loss: 0.1826\n",
      "train accuracy = 89.23076923076924\n",
      "train accuracy = 85.93406593406593\n",
      "train accuracy = 80.43956043956044\n",
      "train accuracy = 72.3076923076923\n",
      "train accuracy = 72.74725274725274\n",
      "train accuracy = 77.58241758241759\n",
      "train accuracy = 82.41758241758241\n",
      "train accuracy = 86.5934065934066\n",
      "train accuracy = 89.8901098901099\n",
      "train accuracy = 90.98901098901099\n",
      "Epoch [20/2000], Loss: 0.1540\n",
      "train accuracy = 90.10989010989012\n",
      "train accuracy = 89.67032967032968\n",
      "train accuracy = 88.35164835164835\n",
      "train accuracy = 87.25274725274726\n",
      "train accuracy = 87.91208791208791\n",
      "train accuracy = 91.42857142857143\n",
      "train accuracy = 92.74725274725274\n",
      "train accuracy = 92.52747252747253\n",
      "train accuracy = 91.86813186813187\n",
      "train accuracy = 92.3076923076923\n",
      "Epoch [30/2000], Loss: 0.1271\n",
      "train accuracy = 92.74725274725274\n",
      "train accuracy = 91.64835164835165\n",
      "train accuracy = 91.42857142857143\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 92.74725274725274\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 92.74725274725274\n",
      "train accuracy = 92.52747252747253\n",
      "Epoch [40/2000], Loss: 0.1071\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 92.74725274725274\n",
      "Epoch [50/2000], Loss: 0.0921\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 92.52747252747253\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.4065934065934\n",
      "Epoch [60/2000], Loss: 0.0821\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.4065934065934\n",
      "Epoch [70/2000], Loss: 0.0747\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.06593406593406\n",
      "Epoch [80/2000], Loss: 0.0696\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 93.4065934065934\n",
      "Epoch [90/2000], Loss: 0.0662\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.06593406593406\n",
      "Epoch [100/2000], Loss: 0.0626\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 94.06593406593406\n",
      "Epoch [110/2000], Loss: 0.0591\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.72527472527472\n",
      "Epoch [120/2000], Loss: 0.0551\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "Epoch [130/2000], Loss: 0.0521\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 94.94505494505493\n",
      "Epoch [140/2000], Loss: 0.0499\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.72527472527472\n",
      "Epoch [150/2000], Loss: 0.0482\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.28571428571428\n",
      "Epoch [160/2000], Loss: 0.0475\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "Epoch [170/2000], Loss: 0.0463\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.28571428571428\n",
      "Epoch [180/2000], Loss: 0.0451\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.06593406593406\n",
      "Epoch [190/2000], Loss: 0.0464\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 95.16483516483515\n",
      "Epoch [200/2000], Loss: 0.0495\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.5054945054945\n",
      "Epoch [210/2000], Loss: 0.0467\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "Epoch [220/2000], Loss: 0.0445\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.94505494505493\n",
      "Epoch [230/2000], Loss: 0.0414\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 95.16483516483515\n",
      "Epoch [240/2000], Loss: 0.0413\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.6043956043956\n",
      "Epoch [250/2000], Loss: 0.0388\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.16483516483515\n",
      "Epoch [260/2000], Loss: 0.0382\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.16483516483515\n",
      "Epoch [270/2000], Loss: 0.0354\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.6043956043956\n",
      "Epoch [280/2000], Loss: 0.0501\n",
      "train accuracy = 93.4065934065934\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 90.76923076923077\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.84615384615384\n",
      "Epoch [290/2000], Loss: 0.0397\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 90.76923076923077\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.62637362637362\n",
      "Epoch [300/2000], Loss: 0.0446\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.16483516483515\n",
      "Epoch [310/2000], Loss: 0.0382\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 94.94505494505493\n",
      "Epoch [320/2000], Loss: 0.0364\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.16483516483515\n",
      "Epoch [330/2000], Loss: 0.0340\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [340/2000], Loss: 0.0329\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.6043956043956\n",
      "Epoch [350/2000], Loss: 0.0336\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 93.84615384615384\n",
      "train accuracy = 93.18681318681318\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 93.62637362637362\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 93.84615384615384\n",
      "Epoch [360/2000], Loss: 0.0507\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 92.96703296703296\n",
      "train accuracy = 93.18681318681318\n",
      "Epoch [370/2000], Loss: 0.0401\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.38461538461539\n",
      "Epoch [380/2000], Loss: 0.0358\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.04395604395604\n",
      "Epoch [390/2000], Loss: 0.0313\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 95.6043956043956\n",
      "Epoch [400/2000], Loss: 0.0309\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 94.06593406593406\n",
      "Epoch [410/2000], Loss: 0.0361\n",
      "train accuracy = 94.72527472527472\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 96.04395604395604\n",
      "Epoch [420/2000], Loss: 0.0297\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.6043956043956\n",
      "Epoch [430/2000], Loss: 0.0276\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "Epoch [440/2000], Loss: 0.0264\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "Epoch [450/2000], Loss: 0.0358\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 94.06593406593406\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 94.5054945054945\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.04395604395604\n",
      "Epoch [460/2000], Loss: 0.0290\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 94.28571428571428\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.04395604395604\n",
      "Epoch [470/2000], Loss: 0.0364\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 94.94505494505493\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [480/2000], Loss: 0.0291\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "Epoch [490/2000], Loss: 0.0310\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 95.16483516483515\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [500/2000], Loss: 0.0273\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 95.38461538461539\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.6043956043956\n",
      "train accuracy = 95.38461538461539\n",
      "Epoch [510/2000], Loss: 0.0290\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 95.82417582417582\n",
      "Epoch [520/2000], Loss: 0.0269\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [530/2000], Loss: 0.0261\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "Epoch [540/2000], Loss: 0.0252\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [550/2000], Loss: 0.0249\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [560/2000], Loss: 0.0248\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "Epoch [570/2000], Loss: 0.0246\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [580/2000], Loss: 0.0247\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [590/2000], Loss: 0.0249\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [600/2000], Loss: 0.0244\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 95.82417582417582\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [610/2000], Loss: 0.0245\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 95.82417582417582\n",
      "Epoch [620/2000], Loss: 0.0252\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [630/2000], Loss: 0.0247\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [640/2000], Loss: 0.0243\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [650/2000], Loss: 0.0243\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [660/2000], Loss: 0.0242\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [670/2000], Loss: 0.0242\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [680/2000], Loss: 0.0244\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [690/2000], Loss: 0.0241\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [700/2000], Loss: 0.0241\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [710/2000], Loss: 0.0239\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [720/2000], Loss: 0.0239\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [730/2000], Loss: 0.0237\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [740/2000], Loss: 0.0238\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [750/2000], Loss: 0.0236\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [760/2000], Loss: 0.0236\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [770/2000], Loss: 0.0234\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [780/2000], Loss: 0.0235\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [790/2000], Loss: 0.0233\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [800/2000], Loss: 0.0232\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [810/2000], Loss: 0.0231\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [820/2000], Loss: 0.0231\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [830/2000], Loss: 0.0230\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [840/2000], Loss: 0.0229\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [850/2000], Loss: 0.0228\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [860/2000], Loss: 0.0228\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [870/2000], Loss: 0.0227\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [880/2000], Loss: 0.0227\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [890/2000], Loss: 0.0225\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [900/2000], Loss: 0.0224\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [910/2000], Loss: 0.0224\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [920/2000], Loss: 0.0224\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [930/2000], Loss: 0.0224\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [940/2000], Loss: 0.0222\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [950/2000], Loss: 0.0220\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [960/2000], Loss: 0.0221\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [970/2000], Loss: 0.0221\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [980/2000], Loss: 0.0220\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [990/2000], Loss: 0.0218\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1000/2000], Loss: 0.0218\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1010/2000], Loss: 0.0218\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [1020/2000], Loss: 0.0218\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1030/2000], Loss: 0.0213\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1040/2000], Loss: 0.0222\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [1050/2000], Loss: 0.0214\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [1060/2000], Loss: 0.0213\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "Epoch [1070/2000], Loss: 0.0215\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1080/2000], Loss: 0.0206\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1090/2000], Loss: 0.0206\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [1100/2000], Loss: 0.0210\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1110/2000], Loss: 0.0200\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1120/2000], Loss: 0.0205\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1130/2000], Loss: 0.0197\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.7032967032967\n",
      "Epoch [1140/2000], Loss: 0.0242\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1150/2000], Loss: 0.0278\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.26373626373626\n",
      "Epoch [1160/2000], Loss: 0.0218\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1170/2000], Loss: 0.0221\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "Epoch [1180/2000], Loss: 0.0253\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1190/2000], Loss: 0.0221\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1200/2000], Loss: 0.0233\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1210/2000], Loss: 0.0221\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1220/2000], Loss: 0.0201\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1230/2000], Loss: 0.0195\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 96.04395604395604\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1240/2000], Loss: 0.0256\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1250/2000], Loss: 0.0191\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "Epoch [1260/2000], Loss: 0.0217\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1270/2000], Loss: 0.0211\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1280/2000], Loss: 0.0249\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1290/2000], Loss: 0.0211\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [1300/2000], Loss: 0.0201\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1310/2000], Loss: 0.0205\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1320/2000], Loss: 0.0218\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1330/2000], Loss: 0.0236\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1340/2000], Loss: 0.0198\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1350/2000], Loss: 0.0210\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1360/2000], Loss: 0.0231\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1370/2000], Loss: 0.0195\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1380/2000], Loss: 0.0182\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "Epoch [1390/2000], Loss: 0.0203\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1400/2000], Loss: 0.0186\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1410/2000], Loss: 0.0182\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.7032967032967\n",
      "Epoch [1420/2000], Loss: 0.0194\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "Epoch [1430/2000], Loss: 0.0206\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1440/2000], Loss: 0.0215\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1450/2000], Loss: 0.0204\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1460/2000], Loss: 0.0230\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1470/2000], Loss: 0.0211\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.36263736263736\n",
      "Epoch [1480/2000], Loss: 0.0183\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 98.02197802197801\n",
      "Epoch [1490/2000], Loss: 0.0184\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1500/2000], Loss: 0.0186\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1510/2000], Loss: 0.0178\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "Epoch [1520/2000], Loss: 0.0178\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1530/2000], Loss: 0.0180\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1540/2000], Loss: 0.0189\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 96.92307692307692\n",
      "Epoch [1550/2000], Loss: 0.0211\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1560/2000], Loss: 0.0215\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.48351648351648\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1570/2000], Loss: 0.0210\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "Epoch [1580/2000], Loss: 0.0162\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1590/2000], Loss: 0.0185\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.14285714285714\n",
      "Epoch [1600/2000], Loss: 0.0170\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 96.26373626373626\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 96.7032967032967\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1610/2000], Loss: 0.0174\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1620/2000], Loss: 0.0191\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 96.92307692307692\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "Epoch [1630/2000], Loss: 0.0189\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "Epoch [1640/2000], Loss: 0.0183\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1650/2000], Loss: 0.0193\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "Epoch [1660/2000], Loss: 0.0191\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1670/2000], Loss: 0.0182\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 97.36263736263736\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.24175824175823\n",
      "Epoch [1680/2000], Loss: 0.0190\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.14285714285714\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1690/2000], Loss: 0.0174\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.58241758241758\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 97.8021978021978\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.24175824175823\n",
      "Epoch [1700/2000], Loss: 0.0165\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 97.8021978021978\n",
      "Epoch [1710/2000], Loss: 0.0166\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1720/2000], Loss: 0.0160\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.02197802197801\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1730/2000], Loss: 0.0160\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "Epoch [1740/2000], Loss: 0.0163\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "Epoch [1750/2000], Loss: 0.0165\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "Epoch [1760/2000], Loss: 0.0163\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "Epoch [1770/2000], Loss: 0.0161\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.24175824175823\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1780/2000], Loss: 0.0158\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1790/2000], Loss: 0.0157\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1800/2000], Loss: 0.0156\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "Epoch [1810/2000], Loss: 0.0155\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1820/2000], Loss: 0.0153\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1830/2000], Loss: 0.0153\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1840/2000], Loss: 0.0151\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1850/2000], Loss: 0.0151\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1860/2000], Loss: 0.0150\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1870/2000], Loss: 0.0149\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1880/2000], Loss: 0.0148\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1890/2000], Loss: 0.0147\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1900/2000], Loss: 0.0147\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1910/2000], Loss: 0.0146\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1920/2000], Loss: 0.0145\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1930/2000], Loss: 0.0145\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1940/2000], Loss: 0.0144\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1950/2000], Loss: 0.0144\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1960/2000], Loss: 0.0143\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1970/2000], Loss: 0.0143\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "Epoch [1980/2000], Loss: 0.0142\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "Epoch [1990/2000], Loss: 0.0142\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.68131868131869\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "train accuracy = 98.46153846153847\n",
      "train accuracy = 98.9010989010989\n",
      "Epoch [2000/2000], Loss: 0.0144\n",
      "train accuracy = 98.46153846153847\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP\n",
    "epochs = 2000\n",
    "training_accuracies = []\n",
    "testing_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_features = Tensor(X_train, requires_grad=True) \n",
    "    train_labels   = Tensor(y_train.reshape(-1,1), requires_grad=False)\n",
    "    \n",
    "    predictions = model.forward(train_features)\n",
    "    loss = criterion(predictions, train_labels)\n",
    "    \n",
    "    # Backward pass & optimizer update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.data:.4f}\")\n",
    "\n",
    "    # Train accuracy calculation\n",
    "    pred_train_labels = (predictions.data >= 0.5).astype(int).ravel()\n",
    "    train_accuracy = (pred_train_labels == y_train).mean() * 100\n",
    "    training_accuracies.append(train_accuracy)\n",
    "    print(f\"train accuracy = {train_accuracy}\")\n",
    "    \n",
    "    # Test accuracy calculation\n",
    "    test_features = Tensor(X_test)\n",
    "    test_predictions = model.forward(test_features)\n",
    "    pred_test_labels = (test_predictions.data >= 0.5).astype(int).ravel()\n",
    "    test_accuracy = (pred_test_labels == y_test).mean() * 100\n",
    "    testing_accuracies.append(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f09c1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Accuracy: 98.25%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FINAL EVALUATION\n",
    "correct = 0\n",
    "total = len(y_test)\n",
    "\n",
    "test_inputs = Tensor(X_test)\n",
    "test_outputs = model.forward(test_inputs)\n",
    "test_pred_labels = (test_outputs.data >= 0.5).astype(int).ravel()\n",
    "\n",
    "correct = (test_pred_labels == y_test).sum()\n",
    "accuracy = (correct / total) * 100\n",
    "print(f\"\\nFinal Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(training_accuracies, label=\"Train accuracy\", color='red')\n",
    "plt.plot(testing_accuracies, label=\"Test accuracy\", color='blue', linestyle='dashed')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Testing Accuracy on WDBC Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d7328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
